2.**Discrete random variables and their Distribution**
===

## < *Contents* >
- [1. Distribution of a random variable(확률변수의 분포)](#%EF%B8%8F-1-distribution-of-a-random-variable확률변수의-분포)
- [2. Distribution of a random vector(확률벡터의 분포)](#%EF%B8%8F-2-distribution-of-a-random-vector확률벡터의-분포)
- [3. Expectation and Variance(기댓값과 분산)](#%EF%B8%8F-3-expectation-and-variance기댓값과-분산)  

---  

## ✔️ 1. **Distribution of a random variable(확률변수의 분포)**  
### 1) **Random Variable(확률변수)**
- 어떤 시행의 결과에 따른 값과, 그 값에 대응하는 확률이 정해지는 변수를 "확률변수"라고 한다.  
- A random variable is a function of an outcome ω.  
(확률변수는 결과 ω에 대한 함수이다. → 정의역 : 표본공간, 공역 : 실수 전체의 집합)
<p align="center"><img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X%20%3D%20f(%5Comega)%0D"></p>  

- 확률변수는 대개 알파벳 대문자(X, Y, Z 등)로 나타내고, 확률변수가 취하는 값은 소문자(x, y, z 등)로 나타낸다.   

- (ex) 3개의 Fair coin 던지기를 할 때, 동전의 앞면이 나오는 경우를 센다고 해보자.
    - <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">를 앞면이 나오는 동전의 개수라고 할 때, 다음과 같이 각 사건에 대한 확률을 구해볼 수 있다.  

    <p align="center"><img src="../Additional_files/images/probability4.png" width = 600></p>  
</br>  

### 2) **Distribution of X**
- Collection of all the probabilities related to <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> is the distribution of <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> .  

- The function below is the **probability mass function(확률질량함수)**, or **pmf**.
<p align="center"><img style="background: None;" src="https://render.githubusercontent.com/render/math?math=P(x)%20%3D%20P\{X%20%3D%20x\}%0D"></p>  

- The **cummulative distribution function(누적분포함수)**, or **cdf** is defined as   
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=F(x)%20%3D%20P%5C%7BX%20%5Cleq%20x%20%5C%7D%20%3D%20%5Csum_%7By%20%5Cleq%20x%7D%20P(y)%0D"></p>  


- The set of possible values of <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> is called the support of the distribution <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=F">  
(<img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">가 가질 수 있는 모든 가능한 값들을 분포 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=F">의 "support"라고 한다.)

- <img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Csum_%7Bx%7D%5E%7B%7D%20P(x)%20%3D%20%5Csum_%7Bx%7D%5E%7B%7D%20P%5C%7BX%20%3D%20x%5C%7D%20%3D%201%2C%20%5Cquad%20%5Clim_%7Bx%20%5Cdownarrow%20-%20%5Cinfty%7D%20F(x)%20%3D%200%20%5C%2C%5C%2C%20and%20%5C%2C%20%5Clim_%7Bx%20%5Cuparrow%20%2B%20%5Cinfty%7D%20F(x)%20%3D%201"> 

<p align="center"><img src="../Additional_files/images/probability5.png" width = 500></p>  
</br>

### 3) **Types of random variables(확률변수의 종류)**
- **Discrete random variable(이산확률변수)**  
    - A variable which may take only a countable number of distinct values.  
    (확률변수 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">가 취할 수 있는 값이 유한한(셀 수 있는) 경우) 
    - (ex) 프린터가 출력할 출력물의 개수  
</br>

- **Continuous random variable(연속확률변수)**  
    - A variable which takes an infinite number of possible values.  
    (확률변수 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">가 취할 수 있는 값이 무한한(셀 수 없는) 경우)
    - (ex) 프린터가 출력물을 출력하는데 걸리는 시간
</br>

## ✔️ 2. **Distribution of a random vector(확률벡터의 분포)**  

### 1) **Joint distribution and Marginal distribution(결합 분포와 주변 분포)**
- If <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> and <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y"> are random variables, the pair(<img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">, <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y">) is a random vector.  
(확률변수 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">, <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y">로 이루어진 벡터 (<img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">, <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y">)를 "확률벡터"라고 한다.)  

- Its distribution is called the **joint distribution** of <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> and <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y">.  
Individual distributions of <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> and <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y"> are then called the **marginal distributions**.  
(두 개 이상의 확률변수를 동시에 고려한 확률분포를 "결합 분포"라고 하며,  
 각각의 확률변수에 대한 분포를 "주변 분포"라고 한다.)  

<p align="center"><img src="../Additional_files/images/probability6.png" width = 250></p>  

- <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=P(x, y) = P\{(X, Y) = (x, y)\} = P\{X = x \cap Y = y\}">  

- <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=\sum_{x} \sum_{y} P(x, y) = 1">  (Since, <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=\{(X, Y) = (x, y)\}"> are exhaustive and mutually exclusive events.)

- All the concepts extend to a vector <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=(X_1, X_2, ... , X_n)"> of n components and its joint distribution.  
</br>

### 2) **Addition Rule**
- Computing marginal probabilities from the joint distribution.  
(결합 분포를 통해 주변 확률을 구하는 방법이다.)  

<p align="center"><img src="../Additional_files/images/probability7.png" width = 600></p>  
</br> 

### 3) **Independence of random variables(확률변수의 독립)**
- Random variables <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> and <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y"> are independent if they satisfy the expression below for all values of <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> and <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y">  
(확률변수 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">, <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y">가 모든 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=x">, <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=y">에 대해 다음 식을 만족하면 두 확률변수는 서로 "독립"이다.)
<p align="center"><img style="background: None;" src="https://render.githubusercontent.com/render/math?math=P_{(X, Y)}(x, y) = P_{X}(x) \cdot P_{Y}(y)"></p>  

- In other words, variable <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X"> and <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y"> take their values independently of each other.  
(두 확률변수가 어떤 값을 가질지에 대해서 서로 상관이 없다.)  

<p align="center"><img src="../Additional_files/images/probability8.png" width = 650></p>  
</br>

## ✔️ 3. **Expectation and Variance(기댓값과 분산)**  
### 1) **Expectation(기댓값)**
- Expectation or expected value of a random variable X is its mean, the average value.  
(이산확률변수의 기댓값은 표본공간의 원소 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=x_i">의 가중 평균을 의미한다.)  

- Expectation discrete case  
<p align="center"><img src="https://render.githubusercontent.com/render/math?math=%5Cmu%20%3D%20E(X)%20%3D%20%5Csum_%7Bx%7D%20xP(x)%0D"></p>


<p align="center"><img src="../Additional_files/images/probability9.png" width = 600></p>  
</br>

### 2) **Expectation of function(함수의 기댓값)**
- If <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y"> is a function of <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">, expectation of <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y = g(X)">  is computed by a similar formula,  
(<img style="background: None;" src="https://render.githubusercontent.com/render/math?math=X">에 대한 함수 <img style="background: None;" src="https://render.githubusercontent.com/render/math?math=Y">의 기댓값도 다음과 같이 구할 수 있다.) 
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=E%5C%7Bg(X)%5C%7D%20%3D%20%5Csum_%7Bx%7D%20g(x)P(x)%0D"></p>  
</br>

### 3) Properties of expectations(기댓값의 성질)   
- Properties of expectations
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=E(aX%20%2B%20bY%20%2B%20c)%20%3D%20aE(X)%20%2B%20bE(Y)%20%2B%20c%0D"></p>  
<img style="" src="https://render.githubusercontent.com/render/math?math=\quad \quad \quad"> In particular,

<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=E(X%20%2B%20Y)%20%3D%20E(X)%20%2B%20E(Y)%0D"></p>
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=E(aX) = aE(X)"></p>   
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=E(c) = c"></p>   
<img style="" src="https://render.githubusercontent.com/render/math?math=\quad \quad \quad"> For independent X and Y  
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=E(XY) = E(X)E(Y)"></p>  

- proof )  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20E(aX%20%2B%20bY%20%2B%20c)%20%3D%20%5Csum_x%20%5Csum_y%20(ax%20%2B%20by%20%2B%20c)P_%7B(X%2C%20Y)%7D(x%2C%20y)">  
<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20%3D%20%5Csum_x%20ax%20%5Csum_y%20P_%7B(X%2C%20Y)%7D%20(x%2C%20y)%20%2B%20%5Csum_y%20by%20%5Csum_x%20P_%7B(X%2C%20Y)%7D(x%2C%20y)%20%2B%20c%20%5Csum_x%20%5Csum_y%20P_%7B(X%2C%20Y)%7D(x%2C%20y)">  
<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20%3D%20a%20%5Csum_x%20xP_%7BX%7D(x)%20%2B%20b%20%5Csum_y%20yP_%7BY%7D(y)%20%2B%20c%20.">   

</br>
<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20E(XY)%20%3D%20%5Csum_x%20%5Csum_y%20(xy)P_X(x)%20P_Y(y)%20%3D%20%5Csum_x%20xP_X(x)%20%5Csum_y%20yP_Y(y)%20%3D%20E(X)E(Y).">  

</br>  

### 4) **Variance and standard deviation(분산과 표준편차)**  
- **Variance(분산)**
    - 편차의 제곱의 평균값
    - 기댓값은 확률변수의 위치를 나타내고 분산은 그것이 얼마나 넓게 퍼져 있는지를 나타낸다.
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=%5Csigma^2%20%3D%20Var(X)%20%3D%20E(X%20-%20EX)%5E2%20%3D%20%5Csum_x%20(x%20-%20%5Cmu)%5E2P(x)%0D"></p>  
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=Var(X) = E(X^2) - {\mu}^2"></p>
</br>

- **Standard deviation(표준편차)**
    - 분산의 제곱근 값 (다시 원래 크기로 만들어 준다.)
    - 기댓값에서 얼마나 떨어져 있는지를 나타낸다.  
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=\sigma = Std(X) = \sqrt{Var(X)}"></p>  

### 5) **Covariance and correlation(공분산과 상관관계)**  
- **Covariance(공분산)**
    - 확률변수 X의 편차와 Y의 편차를 곱한 것의 평균값
    - 2개의 확률변수의 선형 관계를 나타낸다.
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=\sigma_{XY} = Cov(X, Y) = E\{(X - EX)(Y - EY)\}"></p>
<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=\quad \quad \quad \quad \quad \quad= E(XY) - E(X)E(Y)"></p>

<p align="center"><img src="../Additional_files/images/probability10.png" width = 600></p>  
</br>  

- **Correlation coefficient(상관계수)**
    - 두 변수 <img style="" src="https://render.githubusercontent.com/render/math?math=X">, <img style="" src="https://render.githubusercontent.com/render/math?math=Y"> 사이의 상관관계의 정도를 나타내는 수치  
    - 상관계수는 피어슨(Karl Pearson)에 의하여 제안되었기 때문에 피어슨 상관계수라고도 한다.

<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=\rho = \frac{Cov(X, Y)}{(StdX)(StdY)}"></p>  
<p align="center"><img src="../Additional_files/images/probability11.png" width = 500></p>  
</br>  

### 6) Properties of variances and covariances(분산과 공분산의 성질)
- Properties of variances and covariances   

<img style="" src="https://render.githubusercontent.com/render/math?math=\quad \quad \quad Var(aX%20%2B%20bY%20%2B%20c)%20%3D%20a%5E2Var(X)%20%2B%20b%5E2Var(Y)%20%2B%202abCov(X%2C%20Y)%0D">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20Cov(aX%20%2B%20bY.%20cZ%20%2B%20dW)%20%3D%20acCov(X%2C%20Z)%20%2B%20adCov(X%2C%20W)%20%2B%20bcCov(Y%2C%20Z)%20%2B%20bdCov(Y%2C%20W)">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20Cov(X%2C%20Y)%20%3D%20Cov(Y%2C%20X)%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cquad%20%5Crho(X%2C%20Y)%20%3D%20%5Crho(Y%2C%20X)">

<img style="" src="https://render.githubusercontent.com/render/math?math=\quad \quad"> In particular,  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20Var(aX%20%2B%20b)%20%3D%20a%5E2Var(X)">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20Cov(aX%20%2B%20b%2C%20cY%20%2B%20d)%20%3D%20acCov(X%2C%20Y)">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20%5Crho(aX%20%2B%20b%2C%20cY%20%2B%20d)%20%3D%20%5Crho(X%2C%20Y)">  

<img style="" src="https://render.githubusercontent.com/render/math?math=\quad \quad"> For independent X and Y,  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=\quad \quad \quad Cov(X%2C%20Y)%20%3D%200">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=\quad \quad \quad Var(X%20%2B%20Y)%20%3D%20Var(X)%20%2B%20Var(Y)">  

</br>

- proof )  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20Var(aX%20%2B%20bY%20%2B%20c)%20%3D%20E%5C%7B(aX%20%2B%20bY%20%2B%20c)%20-%20E(aX%20%2B%20bY%20%2B%20c)%5C%7D%5E2">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20%3D%20E%5C%7B(aX%20-%20aEX)%20%2B%20(bY%20-%20bEY)%20%2B%20(c%20-%20c)%5C%7D%5E2">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20%3D%20E%5C%7Ba(X%20-%20EX)%5C%7D%5E2%20%2B%20E%5C%7Bb(Y%20-%20EY)%5C%7D%5E2%20%2B%20E%5C%7Ba(X%20-%20EX)b(Y%20-%20EY)%5C%7D%20%2B%20E%5C%7Ba(Y%20-%20EY)b(X%20-%20EX)%5C%7D">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20%3D%20a%5E2Var(X)%20%2B%20b%5E2Var(Y)%20%2B%202abCov(X%2C%20Y)">   

</br>

### 7) **Chebyshev's inequality(쳬비쇼프 부등식)**  

- Any random variable <img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=X"> with expectation <img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=\mu = E(X)"> and variance <img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=\sigma^2 = Var(X)"> belongs to the
interval  
<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=\mu \pm \epsilon = [\mu - \epsilon, \mu + \epsilon]"> with probability of at least <img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=1 - (\sigma/\epsilon)^2">
. That is,  

<p align="center"><img style="" src="https://render.githubusercontent.com/render/math?math=P%5C%7B%7CX%20-%20%5Cmu%7C%20%3E%20%5Cepsilon%20%5C%7D%20%5Cleq%20(%5Cfrac%7B%5Csigma%7D%7B%5Cepsilon%7D)%5E2%0D"></p>   
</br>

<img style="" src="https://render.githubusercontent.com/render/math?math=\quad \quad "> for any distribution with expectation <img style="" src="https://render.githubusercontent.com/render/math?math=\mu"> and variance <img style="" src="https://render.githubusercontent.com/render/math?math=\sigma^2"> and for any positive <img style="" src="https://render.githubusercontent.com/render/math?math=\epsilon">  

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%7B%5Csigma%7D%5E2%20%3D%20%5Csum_%7Ball%20%5C%2C%20x%7D(x%20-%20%5Cmu)%5E2P(x)%20%5Cgeq%20%5Csum_%7Bonly%20%5C%2C%20x%3A%7Cx-%5Cmu%3E%5Cepsilon%7D%20(x%20-%20%5Cmu)%5E2P(x)">

<img style="transform: translateY(0.1em);" src="https://render.githubusercontent.com/render/math?math=%5Cquad%20%5Cquad%20%5Cquad%20%5Cquad%20%5Cgeq%20%5Csum_%7Bx%3A%7Cx-%5Cmu%7C%3E%5Cepsilon%7D%20%5Cepsilon%5E2%20P(x)%20%3D%20%5Cepsilon%5E2%5Csum_%7Bx%3A%7Cx-%5Cmu%7C%3E%5Cepsilon%7D%20P(x)%20%3D%20%7B%5Cepsilon%7D%5E2%20P%5C%7B%7Cx-%5Cmu%7C%20%3E%20%5Cepsilon%5C%7D">